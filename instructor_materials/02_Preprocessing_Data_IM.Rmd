---
title: "RNA-seq analysis in R - Instructor Script"
author: "Stephane Ballereau, Mark Dunning, Oscar Rueda, Ashley Sawle"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output:
  html_notebook:
    toc: yes
  html_document:
    toc: yes
minutes: 300
layout: page
subtitle: Pre-processsing RNA-seq data
editor_options: 
  chunk_output_type: inline
---

# Introduction

* import our counts into R
* manipulate the imported data so that it is in the correct format for DESeq2
* filter out unwanted genes
* run some initial QC on the raw count data

We will also look at the effects of normalisation for composition bias.

# Data import

First, let's load all the packages we will need to analyse the data.

```{r setup, eval = FALSE}
library(tidyverse)
library(DESeq2)
```

## Mouse mammary gland dataset

## Reading in the sample metadata

```{r loadSampleInfo, eval = FALSE}
# Read the sample information into a data frame
sampleinfo <- read.delim("data/SampleInfo.txt", stringsAsFactors=F)
sampleinfo
```

## Reading in the  count data

```{r loadData, eval = FALSE}
# Read the data into R
seqdata <- read.delim("data/GSE60450_Lactation.featureCounts", 
                      comment = "#",
                      stringsAsFactors=F)
head(seqdata)
```

### A quick intro to `dplyr`

Suppose we wanted a new sample table that:

1. Just includes the "basal" samples
2. Only has the columns "CellType" and "Group"
3. Renames the "CellType" column as "Cell"

```{r baseR, eval=FALSE}
newTable <- sampleinfo

basal <- which(newTable$CellType=="basal")
newTable <- newTable[basal, ]

newTable <- newTable[basal, c("CellType", "Group")]

colnames(newTable)[1] <- "Cell"
```

```{r dplyr, eval=FALSE}
newTable <- sampleinfo
newTable <- filter(newTable, CellType=="basal")
newTable <- select(newTable, CellType, Group)
```

```{r pipe, eval=FALSE}
newTable <- sampleinfo %>%
    filter(CellType=="basal") %>%
    select(CellType, Group) %>% 
    rename(Cell=CellType)
```

## Prepare count data

We'll use to new `dplyr` commands:

* `columns_to_rownames` to set the rownames using a named column
* `rename_all` which allows to rename all the columns using a string function

```{r createCountMatrix, eval = FALSE}
countdata <- seqdata %>%
    column_to_rownames("Geneid") %>% # turn the geneid column into rownames
    rename_all(str_remove, ".bam") %>% # remove the ".bam" from the column names
    select(sampleinfo$Sample) %>% # keep sample columns using sampleinfo$Sample
    as.matrix()

head(countdata)
```

Here, we used `str_remove` to remove the unwanted suffix from the column names.
The `stringr` package has a lots of useful functions for manipulating strings 
(text), e.g. `str_replace` or `str_extract`.


# Filtering the genes

With `DESeq` it's not necessary to prefilter - `DESeq` does independent.

```{r filterGenes, eval = FALSE}
dim(countdata)
keep <- rowSums(countdata) > 5
countdata <- countdata[keep,]
dim(countdata)
```

# Quality assessment

## Library sizes bar plot

```{r librarySizes, eval = FALSE}
librarySizes <- colSums(countdata)
barplot(librarySizes, 
        names=names(librarySizes), 
        las=2, 
        main="Barplot of library sizes")
abline(h=20e6, lty=2)
```

## Count distribution boxplots

```{r logTransform, eval = FALSE}
# Get log2 counts per million
logcounts <- log2(countdata + 1)
# lets add the gene ids
rownames(logcounts) <- rownames(countdata)
```

### A Brief Introduction to `ggplot2`

In brief:-

- `logcounts` is our data frame containing the variables we wish to plot
- `aes` mapping between the variables *aes*thetic properties of the plot:
    + the x-axis will be mapped to Sample
    + the y-axis will be mapped to the count data
    + we will need to rearrange the data a bit to create a column of `Sample` and a column `Counts` containing the counts - see below.
- `geom_bar` specifies the particular type of plot we want (in this case a bar 
plot)

`ggplot2` requires the data to be in "tidy" format.

```{r plotLogCounts, eval = FALSE}
# reform the table and add sample data
plotData <- logcounts %>% 
    as.data.frame() %>% 
    gather("Sample", "logCounts") %>% # transforms the matrix to a tidy table
    left_join(sampleinfo, "Sample") # add sampleinfo using "Sample" column to match the rows

# Check distributions of samples using boxplots
# Add a horizontal line at the overall median 
medianCount <- median(plotData$logCounts)
ggplot(plotData, aes(x=Sample, y=logCounts, fill=Status)) +
        geom_boxplot() +
        geom_hline(yintercept = medianCount, colour = "blue")
```

> ### Challenge 1
>
> 1. Use the `DESeq2` function `rlog` to transform the count data. This function
> also normalises for library size.
> 2. Plot the count distribution boxplots with this data
> How has this effected the count distributions?

```{r solutionChallenge1, eval = FALSE}
rlogcounts <- rlog(countdata)

rownames(rlogcounts) <- rownames(countdata)

# reform the table and add sample data
plotData <- rlogcounts %>%
    as.data.frame() %>%
    gather("Sample", "logCounts") %>%
    left_join(sampleinfo, "Sample")

# Check distributions of samples using boxplots
# Add a horizontal line at the overall median
medianCount <- median(plotData$logCounts)
ggplot(plotData, aes(x=Sample, y=logCounts, fill=Group)) +
        geom_boxplot() +
        geom_hline(yintercept = medianCount, colour = "blue")
```


## Principle Component Analysis

```{r pcaPlot, , eval = FALSE}
library(ggfortify)

rlogcounts <- rlog(countdata)

# run PCA
pcDat <- prcomp(t(rlogcounts))
# plot PCA
autoplot(pcDat)
# Lets add colour to look at the clustering for Status
autoplot(pcDat,
         data = sampleinfo, 
         colour="Status", 
         size=5)
# and now status
# Lets add colour to look at the clustering for Cell Type
autoplot(pcDat,
         data = sampleinfo, 
         colour="CellType", 
         size=5)
# We could use shape for one of the factors
autoplot(pcDat,
         data = sampleinfo, 
         colour="Status", 
         shape="CellType",
         size=5)
# Specify some clearer shapes to use that have a black outline and use fill
autoplot(pcDat,
         data = sampleinfo, 
         fill="Status", 
         shape="CellType",
         size=5) +
    scale_shape_manual(values=c(21, 24)) +
    guides(fill = guide_legend(override.aes=list(shape=22)))
```

> ### Discussion
>
> Look at the last PCA plot.
> What is the greatest source of variation?
> Is there something strange going on with the samples?
> Let's identify these samples:

```{r badSamples, , eval = FALSE}
# setting shape to FALSE causes the plot to default to using the labels
autoplot(pcDat,
         data = sampleinfo, 
         colour="CellType", 
         shape=FALSE,
         label.size=6)
```

Let's fix the sample sheet...

```{r correctSampleSheet, eval = FALSE}
sampleinfo <- sampleinfo %>% 
    mutate(CellType=ifelse(Sample=="MCL1.DG", "basal", CellType)) %>% 
    mutate(CellType=ifelse(Sample=="MCL1.LA", "luminal", CellType)) %>% 
    mutate(Group=ifelse(Sample=="MCL1.DG", "basal.virgin", Group)) %>% 
    mutate(Group=ifelse(Sample=="MCL1.LA", "luminal.virgin", Group))
```

...and export it so that we have the correct version for later use.

```{r, exportSampleSheet, eval=FALSE}
write_csv(sampleinfo, "results/SampleInfo_Corrected.txt")
```

Let's look at the PCA now.

we will use the `autoplot` function from the `ggfortify`

```{r correctedPCA, eval = FALSE}
autoplot(pcDat,
         data = sampleinfo, 
         fill="Status", 
         shape="CellType",
         size=5) +
    scale_shape_manual(values=c(21, 24)) +
    guides(fill = guide_legend(override.aes=list(shape=22)))
```

> ### Discussion
>
> What is the greatest source of variation in the data (i.e. what does dimension 1 represent)?
> What is the second greatest source of variation in the data?
>

## PCA beyond the first two dimensions - **probably skip this**

```{r plotPCA3and4, , eval = FALSE}
autoplot(pcDat,
         data = sampleinfo, 
         fill = "Status", 
         shape = "CellType",
         size = 5,
         x = 2,
         y = 3) +
    scale_shape_manual(values=c(21, 24)) +
    guides(fill = guide_legend(override.aes=list(shape=22)))
```

## Interactive MDS Plot with Glimma **maybe skip this**

```{r glimmaMDS, eval=FALSE}
library(Glimma)
glMDSPlot(rlogcounts, 
          labels = sampleinfo$Sample, 
          groups = sampleinfo[,c("CellType", "Status")], 
          folder = "mds")
```

## Hierarchical clustering with heatmaps

select data for the 500 most variable genes and plot the heatmap.

```{r getHMData, eval = FALSE}
# We estimate the variance for each row in the logcounts matrix
countVar <- apply(rlogcounts, 1, var)
# Get the row numbers for the top 500 most variable genes
highVar <- order(countVar, decreasing=TRUE)[1:500]
# Subset logcounts matrix
hmDat <- rlogcounts[highVar,]
```

```{r plotHM, , eval = FALSE}
library(gplots)
library(RColorBrewer)

# Get some nicer colours
mypalette <- brewer.pal(11, "RdYlBu")
# http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3
morecols <- colorRampPalette(mypalette)
# Set up colour vector for celltype variable
col.cell <- c("purple","orange")[sampleinfo$CellType]

# Plot the heatmap
heatmap.2(hmDat, 
          col=rev(morecols(50)),
          trace="column", 
          main="Top 500 most variable genes across samples",
          ColSideColors=col.cell,scale="row")
```

> ### Challenge 2  {.challenge} **Probably skip this**
>
> Redo the heatmap using the top 500 LEAST variable genes.  
> Change the colour scheme to "PiYG" and redo the heatmap. Try `brewer.pal.info` 
> and `display.brewer.all` to see what other colour schemes are available.  
> Change the sample names to `group` using the `labCol` argument  
> Remove the gene names from the righthand side of the plot using `labRow`  

```{r solutionChallenge2,  eval = FALSE}




```

# Convert counts to **DESeqDataSet** object

```{r makeDDSObj, eval = FALSE}
# first lets check that our rows and columns match
all(sampleinfo$Sample == colnames(countdata))
# create the design formula
design <- as.formula(~ CellType)
# create the DESeqDataSet object
ddsObj <- DESeqDataSetFromMatrix(countData = countdata,
                              colData = sampleinfo,
                              design = design)
```

## Normalisation

```{r estimateSizeFactors, eval = FALSE}
# Apply normalisation to DDS object
ddsObj <- estimateSizeFactors(ddsObj)
```

```{r vizNormFactors, eval = FALSE}
ddsObj@colData$sizeFactor
```

## MA plots - raw

```{r plotRawMA, eval = FALSE}
library(limma)
logcounts <- log2(countdata + 1)

par(mfrow=c(1,2))
plotMA(logcounts, array = 7)
abline(h=0,col="grey")
plotMA(logcounts, array = 11)
abline(h=0,col="grey")
```
 
## MA plots - normalised

```{r plotNormedMA, eval = FALSE}
normalizedCounts <- counts(ddsObj, normalized=TRUE) 
logNormalizedCounts <- log2(normalizedCounts + 1)

par(mfrow=c(1,2))
plotMA(logNormalizedCounts, array = 7)
abline(h=0,col="grey")
plotMA(logNormalizedCounts, array = 11)
abline(h=0,col="grey")
```

> ### Challenge 3
>
> Plot the biased and unbiased MA plots both samples side by side to see the 
> before and after normalisation.
>

```{r solutionChallenge3, eval = FALSE}
par(mfrow=c(2,2))
plotMA(logcounts, array = 7, main="MCL1.LA - Raw")
abline(h=0,col="grey")
plotMA(logNormalizedCounts, array = 7, main="MCL1.LA - Normalised")
abline(h=0,col="grey")
plotMA(logcounts, array = 11, main="MCL1.LE - Raw")
abline(h=0,col="grey")
plotMA(logNormalizedCounts, array = 11, main="MCL1.LE - Normalised")
abline(h=0,col="grey")
```

## Export data

```{r saveData, eval=F}
save(countdata, sampleinfo, file="results/preprocessing.RData")
```

